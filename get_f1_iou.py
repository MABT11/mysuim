"""
The provided code performs the evaluation of F1 scores and IoU (Intersection over Union) 
for a set of object categories and different model directories. The code processes the masks 
generated by each model and compares them with manually annotated masks.
"""
###############################################
########## UPDATED THIS FILE ##################
###############################################

from __future__ import print_function, division
import numpy as np
from PIL import Image
import os
# local libs
from utils.data_utils import getPaths
from utils.measure_utils import db_eval_boundary, IoU_bin

## experiment directories
obj_cats = ["RI", "FV", "WR", "RO", "HD"]  # sub-dir
## Directory where the test masks are located
test_dir = "data/test/masks/"
## List of model directories for generated masks
gen_mask_dir = ["output/Pspnet/","output/FCN8/","output/Seg/","output/Unet/","output/VGG16/"]

## Input/output shapes for image resizing
im_res = (320, 240)

# for reading and scaling input images
def read_and_bin(im_path):
    img = Image.open(im_path).resize(im_res)
    img = np.array(img)/255.
    img[img >= 0.5] = 1
    img[img < 0.5] = 0
    return img

# Loop through each object category
for obj_cat in obj_cats:
    real_mask_dir = os.path.join(test_dir, obj_cat)
    
    # Initialize lists to store F1 and IoU values for each model
    F1s, IoUs = [], []
    
    # Loop through each model directory
    for model_dir in gen_mask_dir:
        gen_mask_category_dir = os.path.join(model_dir, obj_cat)
        # Get paths for generated and real masks
        gen_paths = getPaths(gen_mask_category_dir)
        real_paths = getPaths(real_mask_dir)
        
        # Initialize F1s and IoUs for each model
        model_F1s, model_IoUs = [], []
        
        # Loop through each corresponding pair of paths
        for gen_p, real_p in zip(gen_paths, real_paths):
            gen, real = read_and_bin(gen_p), read_and_bin(real_p)
            if np.sum(real) > 0:
                precision, recall, F1 = db_eval_boundary(real, gen)
                iou = IoU_bin(real, gen)
                model_F1s.append(F1)
                model_IoUs.append(iou)
        
        # Calculate and print results for the current model
        avg_model_F1 = 100.0 * np.mean(model_F1s)
        avg_model_IoU = 100.0 * np.mean(model_IoUs)
        print("Object Category: {0}, Model: {1}".format(obj_cat, model_dir))
        print("Avg. F1: {0}".format(avg_model_F1))
        print("Avg. IoU: {0}".format(avg_model_IoU))
        print("-----")
        
        # Append model averages to the category lists
        F1s.append(avg_model_F1)
        IoUs.append(avg_model_IoU)
    
    # Calculate and print results for the current category
    avg_category_F1 = np.mean(F1s)
    avg_category_IoU = np.mean(IoUs)
    print("Category: {0}".format(obj_cat))
    print("Avg. F1: {0}".format(avg_category_F1))
    print("Avg. IoU: {0}".format(avg_category_IoU))
    print("-----")